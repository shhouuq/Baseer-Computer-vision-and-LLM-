{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvQYpX--Le-M",
        "outputId": "9b89b64b-cac3-4c1b-af1d-d5262306a52c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import splitfolders\n",
        "import os\n",
        "from tensorflow.keras.applications import ResNet50, MobileNetV2, VGG19\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0Yub7R6-LXcz"
      },
      "outputs": [],
      "source": [
        "#A function to shuffle the data set\n",
        "\n",
        "def shuffling(path):\n",
        "  # Specify the directory you want to shuffle\n",
        "  directory = path\n",
        "\n",
        "  # Get a list of all files in the directory\n",
        "  files = os.listdir(directory)\n",
        "\n",
        "  # Shuffle the list of files\n",
        "  random.shuffle(files)\n",
        "\n",
        "  # Iterate through the shuffled list and move each file to a new location\n",
        "  for i, file in enumerate(files):\n",
        "      src_path = os.path.join(directory, file)\n",
        "      dst_path = os.path.join(directory, f'shuffled_{i}_{file}')\n",
        "      os.rename(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iu8UgpQjLEhE"
      },
      "outputs": [],
      "source": [
        "regular_path = 'Datasets/Dataset/Regular Traffic' #write down the paths that contains our classes\n",
        "caused_path = 'Datasets/Dataset/Caused Traffic'\n",
        "no_path = 'Datasets/Dataset/No Traffic'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BsOVBwm9MJmy"
      },
      "outputs": [],
      "source": [
        "shuffling(regular_path) #shuffle the classes's dataset\n",
        "shuffling(caused_path)\n",
        "shuffling(no_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc26P6bHMccI",
        "outputId": "74287d87-ca58-4358-ae32-e7aee84ec163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 855 images belonging to 3 classes.\n",
            "Found 61 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCopying files: 348 files [05:34,  1.04 files/s]\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 15s/step - accuracy: 0.6777 - loss: 0.7172 - val_accuracy: 0.9672 - val_loss: 0.2095\n",
            "Epoch 2/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9594 - loss: 0.1973 - val_accuracy: 0.9836 - val_loss: 0.1055\n",
            "Epoch 3/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.9626 - loss: 0.1423 - val_accuracy: 0.9836 - val_loss: 0.0790\n",
            "Epoch 4/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.9661 - loss: 0.1112 - val_accuracy: 0.9672 - val_loss: 0.0721\n",
            "Epoch 5/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9662 - loss: 0.1075 - val_accuracy: 0.9836 - val_loss: 0.0590\n",
            "Epoch 6/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.9857 - loss: 0.0774 - val_accuracy: 0.9836 - val_loss: 0.0545\n",
            "Epoch 7/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.9835 - loss: 0.0831 - val_accuracy: 0.9836 - val_loss: 0.0487\n",
            "Epoch 8/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.9880 - loss: 0.0758 - val_accuracy: 0.9836 - val_loss: 0.0529\n",
            "Epoch 9/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.9922 - loss: 0.0509 - val_accuracy: 0.9836 - val_loss: 0.0477\n",
            "Epoch 10/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.9877 - loss: 0.0518 - val_accuracy: 0.9836 - val_loss: 0.0445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21.5M/21.5M [00:00<00:00, 257MB/s]\n"
          ]
        }
      ],
      "source": [
        "#build classification model (ResNet + MobileNet + VGG19)\n",
        "def build_classification_model():\n",
        "    #load base models\n",
        "    base_model1 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model3 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    #freeze the base layers to prevent training them\n",
        "    for layer in base_model1.layers:\n",
        "        layer.trainable = False\n",
        "    for layer in base_model2.layers:\n",
        "        layer.trainable = False\n",
        "    for layer in base_model3.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    #a shared input for the three models\n",
        "    input_tensor = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "   #apply the input to the three models\n",
        "    x1 = base_model1(input_tensor)\n",
        "    x1 = GlobalAveragePooling2D()(x1)\n",
        "\n",
        "    x2 = base_model2(input_tensor)\n",
        "    x2 = GlobalAveragePooling2D()(x2)\n",
        "\n",
        "    x3 = base_model3(input_tensor)\n",
        "    x3 = GlobalAveragePooling2D()(x3)\n",
        "\n",
        "    #merge the outputs of the three models\n",
        "    merged = tf.keras.layers.concatenate([x1, x2, x3])\n",
        "\n",
        "    #final layer for classification\n",
        "    predictions = Dense(3, activation='softmax')(merged)\n",
        "\n",
        "    #build the final model\n",
        "    model = Model(inputs=input_tensor, outputs=predictions)\n",
        "\n",
        "    #compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "#prepare the data for training\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    'Datasets/Dataset/train',  #the actual path to the data folder\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    'dataset/Datasets/Dataset/val',  \n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "#build and train the classification model\n",
        "model = build_classification_model()\n",
        "\n",
        "#traing the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9JPOGe8yNchi"
      },
      "outputs": [],
      "source": [
        "model.save('classification_model.h5') #save the classification model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
